{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "layout: post\n",
    "title: Parsing PNG images in Mojo\n",
    "categories: [mojo]\n",
    "excerpt: There's currently no direct way of reading image files from Mojo. In this post I go through what's needed to parse a PNG file directly in Mojo without having to go through Python. \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for the past while I've been trying to follow along with the development of Mojo, but so far I've mostly just followed along with the changelog and written some pretty trivial pieces of code. \n",
    "In my last post I said I wanted to try something a bit more substantial, so here goes. \n",
    "\n",
    "I was looking at the [Basalt](https://github.com/basalt-org/basalt) project, which tries to build a Machine Learning framework in pure Mojo, and realized that the only images used so far were MNIST, which come in a weird binary format anyway. Why no other though? As Mojo does not yet support accelerators (like GPUs) Imagenet is probably impractical, but it should be fairly quick to train a CNN on CIFAR-10 on a CPU these days. The CIFAR-10 dataset is available from the [original source](https://www.cs.toronto.edu/~kriz/cifar.html) as either a pickle archive or some custom binary format. I though about writing datasets for these, but it might be more useful to write a PNG parser in Mojo, and then use the version of the dataset hosted on [Kaggle](https://www.kaggle.com/c/cifar-10/). That way the code can be used to open PNG images in general.    \n",
    "\n",
    "\n",
    "# A PNG parser in (pure-ish) Mojo\n",
    "\n",
    "Don't mistake this post for a tutorial: read it as someone discovering the gory details of the PNG standard while learning a new language. If you want to read more about the PNG format, the [wikipedia page](https://en.wikipedia.org/wiki/PNG) is pretty helpful as an overview, and the [W3C page](https://www.w3.org/TR/png/) provides a lot of detail. \n",
    "\n",
    "For reference, this was written with Mojo `24.2.1`, and as Mojo is still changing pretty fast a lot of what is done below might be outdated.\n",
    "\n",
    "The goal here is not to build a tool to display PNGs, but just to read them into an array (or tensor) that can be used for ML purposes, so I will skip over a lot of the more display oriented details. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the data\n",
    "\n",
    "To start let's take a test image. This is the test image from the PIL library, which is an image of the OG [Grace Hopper](https://en.wikipedia.org/wiki/Grace_Hopper): \n",
    "This is a relatively simple PNG, so it should be a good place to start. \n",
    "\n",
    "![hopper](../images/hopper.png \"Hopper\")\n",
    "\n",
    "Now that Mojo has implemented it's version of pathlib in the stdlib, we can actually check if the file exists: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "test_image = Path('../images/hopper.png')\n",
    "print(test_image.exists())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also import the image via Python so we can compare if the outputs we get match the Python case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python import Python\n",
    "var Image = Python.import_module('PIL.Image')\n",
    "var np = Python.import_module('numpy')\n",
    "py_array = np.array(Image.open(\"../images/hopper.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to read the raw bytes. I would have expected the data to be unsigned 8-bit integers, but Mojo reads them as **signed** 8-bit integers. There is however a [proposal to change this](https://github.com/modularml/mojo/pull/2099), so this might change soon. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30605\n"
     ]
    }
   ],
   "source": [
    "with open(test_image, \"r\") as f:\n",
    "    file_contents = f.read_bytes()\n",
    "\n",
    "print(len(file_contents))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the file header\n",
    "\n",
    "PNG files have a signature defined in the first 8-bytes, part of which is the letters PNG in ASCII. Well define a little helper function to convert from bytes to String: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn bytes_to_string(owned list: List[Int8]) -> String:\n",
    "    var word = String(\"\")\n",
    "    for letter in list:\n",
    "        word += chr(int(letter[]))\n",
    "\n",
    "    return word\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure we are actually dealing with a PNG, we can check the bits 1 to 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNG\n"
     ]
    }
   ],
   "source": [
    "png_signature = file_contents[0:8]\n",
    "print(bytes_to_string(png_signature[1:4]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yup, it's telling us it is a PNG file. \n",
    "\n",
    "## Reading chunks\n",
    "\n",
    "So now we read the first \"chunk\", which should be the header. \n",
    "Each chunk consists of four parts, the chunk length (4 bytes), the chunk type (4 bytes), the chunk data (however long the first 4 bytes said it was), and a checksum (called the CRC) computed from the data (4 bytes). \n",
    "\n",
    "| **Length** | **Chunk type** | **Chunk data** | **CRC** |\n",
    "|------------|----------------|----------------|---------|\n",
    "|   4 bytes  |     4 bytes    | _Length_ bytes | 4 bytes |\n",
    "\n",
    "When reading in data with `read_bytes`, the data comes as a list of signed 8-bit integers, but we would like to interpret the data as 32-bit unsigned integers. Below is a helper function to do so (thanks to [Michael Kowalski\n",
    "](https://github.com/mikowals)) for the help.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math.bit import bswap, bitreverse\n",
    "from testing import assert_true\n",
    "\n",
    "\n",
    "fn bytes_to_uint32_be(owned list: List[Int8]) raises -> List[UInt32]:\n",
    "  assert_true(len(list) % 4 == 0, \"List[Int8] length must be a multiple of 4 to convert to List[Int32]\")\n",
    "  var result_length = len(list) // 4\n",
    "  \n",
    "  # get the data pointer with ownership.\n",
    "  # This avoids copying and makes sure only one List owns a pointer to the underlying address.\n",
    "  var ptr_to_int8 = list.steal_data() \n",
    "  var ptr_to_uint32 = ptr_to_int8.bitcast[UInt32]()\n",
    "\n",
    "  var result = List[UInt32]()\n",
    "  result.data = ptr_to_uint32\n",
    "  result.capacity = result_length\n",
    "  result.size = result_length\n",
    "\n",
    "  # swap the bytes in each UInt32 to convert from big-endian to little-endian\n",
    "  for i in range(result_length):\n",
    "    result[i] = bswap(result[i])\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the image header\n",
    "\n",
    "The firs chunk after the file header should always be the image header, so let's have a look at it: \n",
    "\n",
    "Let's see how long the first chunk is: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "read_head = 8\n",
    "chunk_length = bytes_to_uint32_be(file_contents[read_head:read_head+4])[0]\n",
    "print(chunk_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the first chunk is 13 bytes long. Let's see what type it is: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IHDR\n"
     ]
    }
   ],
   "source": [
    "\n",
    "chunk_type = file_contents[read_head+4:read_head+8]\n",
    "print(bytes_to_string(chunk_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IHDR, which confirms that this chunk is the image header. We can now parse the next 13 bytes of header data to get information about the image: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_header = int(read_head+8)\n",
    "end_header = int(read_head+8+chunk_length)\n",
    "header_data = file_contents[start_header:end_header]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first two chunks tell us the width and height of the image respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image width:  128\n",
      "Image height:  128\n"
     ]
    }
   ],
   "source": [
    "print(\"Image width: \", bytes_to_uint32_be(header_data[0:4])[0])\n",
    "print(\"Image height: \", bytes_to_uint32_be(header_data[4:8])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our image is 128x128 pixels in size. \n",
    "\n",
    "The next bytes tell is  the bit depth of each pixel, color type, compression method, filter method, and whether the image is interlaced or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bit depth:  8\n",
      "Color type:  2\n",
      "Compression method:  0\n",
      "Filter method:  0\n",
      "Interlaced:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Bit depth: \", int(header_data[8]))\n",
    "print(\"Color type: \", int(header_data[9]))\n",
    "print(\"Compression method: \", int(header_data[10]))\n",
    "print(\"Filter method: \", int(header_data[11]))\n",
    "print(\"Interlaced: \", int(header_data[12]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the color type is `Truecolor`, so RGB, with a bit depth of 8.\n",
    "\n",
    "Interesting side note: in the [PIL PngImagePlugin](https://github.com/python-pillow/Pillow/blob/main/src/PIL/PngImagePlugin.py) there is a changelog:\n",
    "```\n",
    "# history:\n",
    "# 1996-05-06 fl   Created (couldn't resist it)\n",
    "# 1996-12-14 fl   Upgraded, added read and verify support (0.2)\n",
    "# 1996-12-15 fl   Separate PNG stream parser\n",
    "# 1996-12-29 fl   Added write support, added getchunks\n",
    "# 1996-12-30 fl   Eliminated circular references in decoder (0.3)\n",
    "# 1998-07-12 fl   Read/write 16-bit images as mode I (0.4)\n",
    "# 2001-02-08 fl   Added transparency support (from Zircon) (0.5)\n",
    "# 2001-04-16 fl   Don't close data source in \"open\" method (0.6)\n",
    "# 2004-02-24 fl   Don't even pretend to support interlaced files (0.7)\n",
    "# 2004-08-31 fl   Do basic sanity check on chunk identifiers (0.8)\n",
    "# 2004-09-20 fl   Added PngInfo chunk container\n",
    "# 2004-12-18 fl   Added DPI read support (based on code by Niki Spahiev)\n",
    "# 2008-08-13 fl   Added tRNS support for RGB images\n",
    "# 2009-03-06 fl   Support for preserving ICC profiles (by Florian Hoech)\n",
    "# 2009-03-08 fl   Added zTXT support (from Lowell Alleman)\n",
    "# 2009-03-29 fl   Read interlaced PNG files (from Conrado Porto Lopes Gouvua)\n",
    "```\n",
    "\n",
    "I like the comment from 2004: `Don't even pretend to support interlaced files` and then interlaced PNG being supported about 13 years after PNG reading was added to PIL. \n",
    "I have a feeling I won't be dealing with interlaced files in this post...\n",
    "\n",
    "The final part of this chunk is the CRC32 value, which is the 32-bit [cyclic redundancy check](https://en.wikipedia.org/wiki/Cyclic_redundancy_check). I don't go into too much details, but it's basically an error-detecting code that's added to detect if the chunk data is corrupt. By checking the provided CRC32 value against one we calculate ourselves we can ensure that the data we are reading is not corrupt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRC:  0x4c5cf69c\n"
     ]
    }
   ],
   "source": [
    "start_crc = int(read_head+8+chunk_length)\n",
    "end_crc = int(start_crc+4)\n",
    "header_crc = bytes_to_uint32_be(file_contents[start_crc:end_crc])[0]\n",
    "print(\"CRC: \", hex(header_crc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a little bit of code to calculate the CRC32 value.   \n",
    "This is not the most efficient implementation, but it is simple.   \n",
    "I'll probably do a follow up post where I explain what this does in more detail. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn CRC32(owned data: List[SIMD[DType.int8, 1]], value: SIMD[DType.uint32, 1] = 0xffffffff) -> SIMD[DType.uint32, 1]:\n",
    "    var crc32 = value\n",
    "    for byte in data:\n",
    "        crc32 = (bitreverse(byte[]).cast[DType.uint32]() << 24) ^ crc32\n",
    "        for i in range(8):\n",
    "            \n",
    "            if crc32 & 0x80000000 != 0:\n",
    "                crc32 = (crc32 << 1) ^ 0x04c11db7\n",
    "            else:\n",
    "                crc32 = crc32 << 1\n",
    "\n",
    "    return bitreverse(crc32^0xffffffff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0x4c5cf69c\n"
     ]
    }
   ],
   "source": [
    "print(hex(CRC32(file_contents[read_head+4:end_header])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, so the CRC hexes match, so we know that the data in our IHDR chunk is good. \n",
    "\n",
    "## Reading more chunks\n",
    "\n",
    "Now, reading parts of each chunk will get repetitive, so let's define a struct called `Chunk` to hold the information contained in a chunk, and a function that will parse chunks for us and return the constituent parts: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Chunk:\n",
    "    var length: UInt32\n",
    "    var type: String\n",
    "    var data: List[Int8]\n",
    "    var crc: UInt32\n",
    "    var end: Int\n",
    "\n",
    "    fn __init__(inout self, length: UInt32, chunk_type: String, data : List[Int8], crc: UInt32, end: Int):\n",
    "        self.length = length\n",
    "        self.type = chunk_type\n",
    "        self.data = data\n",
    "        self.crc = crc\n",
    "        self.end = end\n",
    "\n",
    "\n",
    "def parse_next_chunk(owned data: List[Int8], read_head: Int) -> Chunk:\n",
    "    chunk_length = bytes_to_uint32_be(data[read_head:read_head+4])[0]\n",
    "    chunk_type = bytes_to_string(data[read_head+4:read_head+8])\n",
    "    start_data = int(read_head+8)\n",
    "    end_data = int(start_data+chunk_length)\n",
    "    chunk_data = data[start_data:end_data]\n",
    "    start_crc = int(end_data)\n",
    "    end_crc = int(start_crc+4)\n",
    "    chunk_crc = bytes_to_uint32_be(data[start_crc:end_crc])[0]\n",
    "\n",
    "    # Check CRC\n",
    "    assert_true(CRC32(data[read_head+4:end_data]) == chunk_crc, \"CRC32 does not match\")\n",
    "    return Chunk(length=chunk_length, chunk_type=chunk_type, data=chunk_data, crc=chunk_crc, end=end_crc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During chunk creation the CRC32 value for the chunk data is computed, and an issue will be raised if it is different to what is expected. \n",
    "\n",
    "Let's test this to see if it parses the IHDR chunk: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IHDR\n"
     ]
    }
   ],
   "source": [
    "var header_chunk = parse_next_chunk(file_contents, 8)\n",
    "print(header_chunk.type)\n",
    "read_head = header_chunk.end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next few chunks are called \"Ancillary chunks\", and are not strictly necessary. They contain image attributes (like [gamma](https://en.wikipedia.org/wiki/Gamma_correction)) that may be used in rendering the image: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gAMA\n"
     ]
    }
   ],
   "source": [
    "var gamma_chunk = parse_next_chunk(file_contents, read_head)\n",
    "print(gamma_chunk.type)\n",
    "read_head = gamma_chunk.end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cHRM\n"
     ]
    }
   ],
   "source": [
    "var chromacity_chunk = parse_next_chunk(file_contents, read_head)\n",
    "print(chromacity_chunk.type)\n",
    "read_head = chromacity_chunk.end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bKGD\n"
     ]
    }
   ],
   "source": [
    "var background_chunk = parse_next_chunk(file_contents, read_head)\n",
    "print(background_chunk.type)\n",
    "read_head = background_chunk.end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pHYs\n"
     ]
    }
   ],
   "source": [
    "var pixel_size_chunk = parse_next_chunk(file_contents, read_head)\n",
    "print(pixel_size_chunk.type)\n",
    "read_head = pixel_size_chunk.end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The image data chunk\n",
    "\n",
    "The IDAT chunk (there can actually be several of them per image) contains the actual image data. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDAT\n"
     ]
    }
   ],
   "source": [
    "var image_data_chunk = parse_next_chunk(file_contents, read_head)\n",
    "print(image_data_chunk.type)\n",
    "read_head = image_data_chunk.end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decompression\n",
    "\n",
    "PNGs are compressed (losslessly) with the [DEFLATE](https://en.wikipedia.org/wiki/Deflate) compression algorithm. \n",
    "\n",
    "PNGs are first filtered, then compressed, but as we are decoding, we need to first uncompress the data and the undo the filter.\n",
    "\n",
    "This next section is why I said in \"pure-ish\" Mojo: I considered implementing it, but that would be quite a lot of work, so I am hoping that either someone else does this, or that I might dig into this in the future. \n",
    "\n",
    "So for the moment, I am using the [zlib](https://en.wikipedia.org/wiki/Zlib) version of the algorithm through Mojo's foreign function interface (FFI).\n",
    "\n",
    "The following I lightly adapted from the Mojo discord from a thread between Ilya Lubenets and Jack Clayton:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import ffi\n",
    "alias Bytef = Scalar[DType.int8]\n",
    "alias uLong = UInt64\n",
    "alias zlib_type = fn(\n",
    "    _out: Pointer[Bytef], \n",
    "    _out_len: Pointer[UInt64], \n",
    "    _in: Pointer[Bytef], \n",
    "    _in_len: uLong\n",
    ") -> Int\n",
    "fn log_zlib_result(Z_RES: Int, compressing: Bool = True) raises -> NoneType:\n",
    "    var prefix: String = ''\n",
    "    if not compressing:\n",
    "        prefix = \"un\"\n",
    "\n",
    "    if Z_RES == 0:\n",
    "        print('OK ' + prefix.upper() + 'COMPRESSING: Everything ' + prefix + 'compressed fine')\n",
    "    elif Z_RES == -4:\n",
    "        raise Error('ERROR ' + prefix.upper() + 'COMPRESSING: Not enought memory')\n",
    "    elif Z_RES == -5:\n",
    "        raise Error('ERROR ' + prefix.upper() + 'COMPRESSING: Buffer have not enough memory')\n",
    "    else:\n",
    "        raise Error('ERROR ' + prefix.upper() + 'COMPRESSING: Unhandled exception')\n",
    "\n",
    "fn uncompress(data: List[Int8]) raises -> List[UInt8]:\n",
    "    var data_memory_amount: Int = len(data)*4\n",
    "    var handle = ffi.DLHandle('')\n",
    "    var zlib_uncompress = handle.get_function[zlib_type]('uncompress')\n",
    "\n",
    "    var uncompressed = Pointer[Bytef].alloc(data_memory_amount)\n",
    "    var compressed = Pointer[Bytef].alloc(len(data))\n",
    "    var uncompressed_len = Pointer[uLong].alloc(1)\n",
    "    memset_zero(uncompressed, data_memory_amount)\n",
    "    memset_zero(uncompressed_len, 1)\n",
    "    uncompressed_len[0] = data_memory_amount\n",
    "    for i in range(len(data)):\n",
    "        compressed.store(i, data[i])\n",
    "\n",
    "    var Z_RES = zlib_uncompress(\n",
    "        uncompressed,\n",
    "        uncompressed_len,\n",
    "        compressed,\n",
    "        len(data),\n",
    "    )\n",
    "\n",
    "    log_zlib_result(Z_RES, compressing=False)\n",
    "    print('Uncompressed length: ' + str(uncompressed_len[0]))\n",
    "    # Can probably do something more efficient here with pointers, but eh. \n",
    "    var res = List[UInt8]()\n",
    "    for i in range(uncompressed_len[0]):\n",
    "        res.append(uncompressed[i].to_int())\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drumroll... let's see if this worked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK UNCOMPRESSING: Everything uncompressed fine\n",
      "Uncompressed length: 49280\n"
     ]
    }
   ],
   "source": [
    "uncompressed_data = uncompress(image_data_chunk.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a list of uncompressed bytes. However, these are not pixel values yet. \n",
    "The uncompressed data has a length of 49280 bytes. We know we have an RGB image with 8-bit colour depth, so expect $$128 * 128 * 3 = 49152$$ bytes worth of pixel data. Notice that $49280 - 49152 = 128$, and that our image has a shape of `(128, 128)`.  \n",
    "These extra 128 bytes are to let us know what filter was used to transform the byte values in that line of pixels to something that can be efficiently compressed.  \n",
    "\n",
    "### Unfilter\n",
    "\n",
    "The possible filter types specified by the [PNG specification](https://www.w3.org/TR/PNG-Filters.html) are: \n",
    "\n",
    "```\n",
    "   Type    Name\n",
    "   \n",
    "   0       None\n",
    "   1       Sub\n",
    "   2       Up\n",
    "   3       Average\n",
    "   4       Paeth\n",
    "```\n",
    "\n",
    "There is some subtle points to pay attention to in the specification, such as the fact that these filter are applied per byte, and not per pixel value. For 8-bit colour depth this is unimportant, but at 16-bits, this means the first byte of a pixel (the MSB, or most significant byte) will be computed separately from the second byte (the LSB, or least significant byte). I won't go too deep into all the details here, but you can read the details of the specification [here](https://www.w3.org/TR/PNG-Filters.html). \n",
    "\n",
    "I'll briefly explain the basic idea behind each filter: \n",
    "\n",
    "* 0: None\n",
    "   * No filter is applied and each byte value is just the raw pixel value. \n",
    "* 1: Sub\n",
    "   * Each byte has the preceding byte value subtracted from it\n",
    "* 2: Up\n",
    "   * Each byte has the value of the byte above it subtracted from it. \n",
    "* 3: Average: \n",
    "   * Each byte has the (floor) of the average of the bytes above and to the left of it subtracted from it. \n",
    "* 4: Paeth:\n",
    "   * The three neighbouring pixels (left, above and upper left) are used to calculate a value that is subtracted from the pixel. It's a little more involved than the other three. \n",
    "\n",
    "So when decoding the filtered data, we need to reverse the above operations to regain the pixel values. \n",
    "\n",
    "\n",
    "\n",
    "Now that we know that, let's look at our first byte value: \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(uncompressed_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we are dealing with filter type 1 here. \n",
    "Let's decode the first row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "var filter_type = uncompressed_data[0]\n",
    "var scanline = uncompressed_data[1:128*3+1]\n",
    "\n",
    "# Decoded image data\n",
    "var result = List[UInt8](capacity=128*3)\n",
    "# take the first pixels as 0\n",
    "var left: UInt8 = 0\n",
    "var pixel_size: Int = 3\n",
    "var offset: Int = 1\n",
    "\n",
    "for i in range(len(scanline)):\n",
    "    if i >= pixel_size:\n",
    "        left = result[i-pixel_size] \n",
    "\n",
    "    # The specification specifies that the result is modulo 256\n",
    "    # Silimar to the C implementation, we can just add the left pixel to the current pixel,\n",
    "    # and the result will be modulo 256 due to overflow\n",
    "    result.append((uncompressed_data[i + offset] + left))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's confirm that the row we decoded is the same as PIL would do: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(128):\n",
    "    for j in range(3):\n",
    "        assert_true(result[i*3+j] == py_array[0][i][j].__int__(), \"Pixel values do not match\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the general idea of things, let's write this more generally, and do the other filters as well. \n",
    "\n",
    "For an idea of how filters are chosen, read this stackoverflow post and the resources it points to: [How do PNG encoders pick which filter to use?](https://stackoverflow.com/questions/59492926/how-do-png-encoders-pick-which-filter-to-use)\n",
    "\n",
    "I've done these as functions that take 16-bit signed integers. This is important mostly for the case of the Paeth filter, where the standard states: \n",
    "> The calculations within the PaethPredictor function must be performed exactly, without overflow. Arithmetic modulo 256 is to be used only for the final step of subtracting the function result from the target byte value.\n",
    "So basically we need to keep a higher level of precision and then cast back to bytes at the end. \n",
    "\n",
    "\n",
    "I based the implementation on the [iPXE](https://ipxe.org/) implementation of a [png decoder](https://dox.ipxe.org/png_8c_source.html) written in C. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import abs\n",
    "\n",
    "fn undo_trivial(current: Int16, left: Int16 = 0, above: Int16 = 0, above_left: Int16 = 0) -> Int16:\n",
    "    return current\n",
    "\n",
    "fn undo_sub(current: Int16, left: Int16 = 0, above: Int16 = 0, above_left: Int16 = 0) -> Int16:\n",
    "    return current + left\n",
    "\n",
    "fn undo_up(current: Int16, left: Int16 = 0, above: Int16 = 0, above_left: Int16 = 0) -> Int16:\n",
    "    return current + above\n",
    "\n",
    "fn undo_average(current: Int16, left: Int16 = 0, above: Int16 = 0, above_left: Int16 = 0) -> Int16:\n",
    "    return current + ((above + left) >> 1) # Bitshift is equivalent to division by 2\n",
    "\n",
    "fn undo_paeth(current: Int16, left: Int16 = 0, above: Int16 = 0, above_left: Int16 = 0) -> Int16:\n",
    "\n",
    "    var peath: Int16 = left + above - above_left\n",
    "    var peath_a: Int16 = abs(peath - left)\n",
    "    var peath_b: Int16 = abs(peath - above)\n",
    "    var peath_c: Int16 = abs(peath - above_left)\n",
    "    if ( peath_a <= peath_b ) and ( peath_a <= peath_c ):\n",
    "        return (current + left)\n",
    "    elif ( peath_b <= peath_c ): \n",
    "        return (current + above)\n",
    "    else:\n",
    "        return (current + above_left)\n",
    "\n",
    "fn undo_filter(filter_type: UInt8, current: UInt8, left: UInt8 = 0, above: UInt8 = 0, above_left: UInt8 = 0) raises -> UInt8:\n",
    "\n",
    "    var current_int = current.cast[DType.int16]()\n",
    "    var left_int = left.cast[DType.int16]()\n",
    "    var above_int = above.cast[DType.int16]()\n",
    "    var above_left_int = above_left.cast[DType.int16]()\n",
    "    var result_int: Int16 = 0\n",
    "\n",
    "    if filter_type == 0:\n",
    "        result_int= undo_trivial(current_int, left_int, above_int, above_left_int)\n",
    "    elif filter_type == 1:\n",
    "        result_int = undo_sub(current_int, left_int, above_int, above_left_int)\n",
    "    elif filter_type == 2:\n",
    "        result_int = undo_up(current_int, left_int, above_int, above_left_int)\n",
    "    elif filter_type == 3:\n",
    "        result_int = undo_average(current_int, left_int, above_int, above_left_int)\n",
    "    elif filter_type == 4:\n",
    "        result_int = undo_paeth(current_int, left_int, above_int, above_left_int)\n",
    "    else:\n",
    "        raise Error(\"Unknown filter type\")\n",
    "    return result_int.cast[DType.uint8]()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the `undo_filter` function, I was trying to add the separate filters to some kind of Tuple or List so I could just index them (hence the uniform signatures), but wasn't able to figure out how to do this in Mojo yet. \n",
    "\n",
    "So let's apply these to the whole image and confirm that we have the same results as we would get from Python: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Decoded image data\n",
    "# take the first pixels as 0\n",
    "var pixel_size: Int = 3\n",
    "\n",
    "# Initialize the previous scanline to 0\n",
    "var previous_result = List[UInt8](0*128)\n",
    "\n",
    "for line in range(128):\n",
    "    var offset =  1 + 1*line + line * 128 * 3\n",
    "    var left: UInt8 = 0\n",
    "    var above_left: UInt8 = 0\n",
    "\n",
    "    #var left: UInt8 = 0\n",
    "    var result = List[UInt8](capacity=128*3)\n",
    "    var scanline = uncompressed_data[offset:offset+128*3]\n",
    "\n",
    "    var filter_type = uncompressed_data[offset - 1]\n",
    "\n",
    "    for i in range(len(scanline)):\n",
    "        if i >= pixel_size:\n",
    "            left = result[i-pixel_size] \n",
    "            above_left = previous_result[i-pixel_size] \n",
    "\n",
    "        result.append(undo_filter(filter_type, uncompressed_data[i + offset], left, previous_result[i], above_left))\n",
    "\n",
    "\n",
    "    previous_result = result\n",
    "    for i in range(128):\n",
    "        for j in range(3):\n",
    "            assert_true(result[i*3+j] == py_array[line][i][j].__int__(), \"Pixel values do not match\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it. If the above runs it means we've sucessfully parsed a PNG file, and at least get the same data out as you would by using Pillow. \n",
    "\n",
    "\n",
    "## Creating a tensor\n",
    "\n",
    "Now ideally we want the above into a Tensor. \n",
    "\n",
    "Lets write a function that will parse the image data and return a Tensor for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensor import Tensor, TensorSpec, TensorShape\n",
    "from utils.index import Index\n",
    "from random import rand\n",
    "\n",
    "var height = 128\n",
    "var width = 128\n",
    "var channels = 3\n",
    "\n",
    "# Declare the grayscale image.\n",
    "var spec = TensorSpec(DType.uint8, height, width, channels)\n",
    "var tensor_image = Tensor[DType.uint8](spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoded image data\n",
    "# take the first pixels as 0\n",
    "var pixel_size: Int = 3\n",
    "\n",
    "# Initialize the previous scanline to 0\n",
    "var previous_result = List[UInt8](0*128)\n",
    "\n",
    "for line in range(128):\n",
    "    var offset =  1 + 1*line + line * 128 * 3\n",
    "    var left: UInt8 = 0\n",
    "    var above_left: UInt8 = 0\n",
    "\n",
    "    #var left: UInt8 = 0\n",
    "    var result = List[UInt8](capacity=128*3)\n",
    "    var scanline = uncompressed_data[offset:offset+128*3]\n",
    "\n",
    "    var filter_type = uncompressed_data[offset - 1]\n",
    "\n",
    "    for i in range(len(scanline)):\n",
    "        if i >= pixel_size:\n",
    "            left = result[i-pixel_size] \n",
    "            above_left = previous_result[i-pixel_size] \n",
    "\n",
    "        result.append(undo_filter(filter_type, uncompressed_data[i + offset], left, previous_result[i], above_left))\n",
    "\n",
    "\n",
    "    previous_result = result\n",
    "    for i in range(128):\n",
    "        for j in range(3):\n",
    "            tensor_image[Index(line, i, j)] = result[i*3+j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm not entirely sure why I need to use `Index` while setting items, but when getting I can just provide indices: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "62\n"
     ]
    }
   ],
   "source": [
    "print(tensor_image[0,1,2])\n",
    "print(py_array[0][1][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there we have it. I will put it all together soon but let's finish parsing the file quickly. \n",
    "\n",
    "## Final chunks\n",
    "There are a few more chunks at this point: text chunks which hold some comments, and an end chunk, which denotes the end of the file: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tEXt\n",
      "comment\n"
     ]
    }
   ],
   "source": [
    "var text_chunk_1 = parse_next_chunk(file_contents, read_head)\n",
    "print(text_chunk_1.type)\n",
    "read_head = text_chunk_1.end\n",
    "print(bytes_to_string(text_chunk_1.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tEXt\n",
      "date:create\n"
     ]
    }
   ],
   "source": [
    "var text_chunk_2 = parse_next_chunk(file_contents, read_head)\n",
    "print(text_chunk_2.type)\n",
    "read_head = text_chunk_2.end\n",
    "print(bytes_to_string(text_chunk_2.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tEXt\n",
      "date:modify\n"
     ]
    }
   ],
   "source": [
    "var text_chunk_3 = parse_next_chunk(file_contents, read_head)\n",
    "print(text_chunk_3.type)\n",
    "read_head = text_chunk_3.end\n",
    "print(bytes_to_string(text_chunk_3.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IEND\n"
     ]
    }
   ],
   "source": [
    "var end_chunk = parse_next_chunk(file_contents, read_head)\n",
    "print(end_chunk.type)\n",
    "read_head = end_chunk.end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mojo",
   "language": "mojo",
   "name": "mojo-jupyter-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "mojo"
   },
   "file_extension": ".mojo",
   "mimetype": "text/x-mojo",
   "name": "mojo"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
