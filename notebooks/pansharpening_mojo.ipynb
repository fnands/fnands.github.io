{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done with Mojo 0.6.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Python implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%python\n",
    "import PIL.Image as Image\n",
    "import numpy as np\n",
    "\n",
    "def prepare_toy_image(image_path: str):\n",
    "    original_image = Image.open(image_path)\n",
    "    original_width, original_height = original_image.size\n",
    "\n",
    "    multispectral_image = original_image.resize((original_width//4, original_width//4))\n",
    "    upscaled_multispectral_image = multispectral_image.resize((original_width, original_height))\n",
    "    panchromatic_image = original_image.convert(\"L\")\n",
    "\n",
    "    original_array = np.array(original_image)\n",
    "    upscaled_multispectral_array = np.array(upscaled_multispectral_image)\n",
    "    panchromatic_array = np.array(panchromatic_image)\n",
    "\n",
    "    return original_array, panchromatic_array, upscaled_multispectral_array\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For completeness we will define a naive python implementation of the pansharpening procedure.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%python \n",
    "def naive_pansharpen_python(panchromatic_array: np.ndarray, upscaled_multispectral_array: np.ndarray, weights: np.ndarray, pansharpened_array: np.ndarray):\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(panchromatic_array.shape[0]):\n",
    "        for j in range(panchromatic_array.shape[1]):\n",
    "            psuedo_pan = 0\n",
    "            sum_weights = 0\n",
    "            for k in range(upscaled_multispectral_array.shape[-1]):\n",
    "                psuedo_pan += upscaled_multispectral_array[i, j, k]*weights[k]\n",
    "                sum_weights += weights[k]\n",
    "\n",
    "            psuedo_pan = psuedo_pan/sum_weights\n",
    "\n",
    "            ratio = panchromatic_array[i, j]/psuedo_pan\n",
    "\n",
    "            for k in range(upscaled_multispectral_array.shape[-1]):\n",
    "                pansharpened_array[i, j, k] = upscaled_multispectral_array[i, j, k] * ratio\n",
    "            \n",
    "    return pansharpened_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%python \n",
    "from timeit import timeit\n",
    "from typing import Callable\n",
    "\n",
    "def benchmark_pansharpen_python(image_path: str, pansharpening_function: Callable, iterations: int=10):\n",
    "\n",
    "    toy_original_array, toy_panchromatic_array, toy_upscaled_multispectral_array = prepare_toy_image(image_path)\n",
    "    toy_pansharpened_array = np.zeros_like(upscaled_multispectral_array)\n",
    "    channel_dependant_luminance_perception = np.array([0.299, 0.587, 0.114])\n",
    "\n",
    "    secs = timeit(lambda: pansharpening_function(panchromatic_array = toy_panchromatic_array, \n",
    "                                                  upscaled_multispectral_array = toy_upscaled_multispectral_array, \n",
    "                                                  weights = channel_dependant_luminance_perception, \n",
    "                                                  pansharpened_array = toy_pansharpened_array), number=iterations)/iterations\n",
    "    \n",
    "    print(secs, \"seconds\")\n",
    "    return secs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: name 'upscaled_multispectral_array' is not defined\n"
     ]
    }
   ],
   "source": [
    "naive_python_time = benchmark_pansharpen_python(\"/home/ferdi/Workspace/pansharpen/treed_brain_512.jpeg\", naive_pansharpen_python, 2).to_float64()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is, of course, a terrible way to do this. \n",
    "Tight loops are extremely slow in Python, and seeing them makes my stomach churn. \n",
    "\n",
    "A better way to do this would be to use Numpy, which is written in C++, and which will vectorize some operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%python\n",
    "def pansharpen_numpy(panchromatic_array: np.ndarray, upscaled_multispectral_array: np.ndarray, weights: np.ndarray, pansharpened_array: np.ndarray):\n",
    "    psuedo_pan_array = np.true_divide((upscaled_multispectral_array*weights).sum(axis=2), weights.sum())\n",
    "    ratio = panchromatic_array/psuedo_pan_array\n",
    "    pansharpened_array[:,:,:] = upscaled_multispectral_array * ratio[:,:,None]\n",
    "    return pansharpened_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: name 'upscaled_multispectral_array' is not defined\n"
     ]
    }
   ],
   "source": [
    "numpy_python_time = benchmark_pansharpen_python(\"/home/ferdi/Workspace/pansharpen/treed_brain_512.jpeg\", pansharpen_numpy, 10).to_float64()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error: Execution was interrupted, reason: signal SIGSEGV: address not mapped to object (fault address: 0x0).\n",
      "The process has been left at the point where it was interrupted, use \"thread return -x\" to return to the state before expression evaluation.\n"
     ]
    }
   ],
   "source": [
    "print(\"Numpy is \", naive_python_time/numpy_python_time, \" times faster tha naive Python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is already a huge win, but we had to implicitly rely on highly optimized C++ libraries to get this done.  \n",
    "\n",
    "Let's first write this in Mojo the same way we did Python. \n",
    "As Mojo aims to be a superset of Python, Python code should ideally just work in Mojo. \n",
    "At the time of writing for Mojo 0.6.0, this is not 100% true yet, but the aim is that this will be the case when Mojo 1.0.0 is released.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python import Python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_toy_image(image_path: String) -> PythonObject:\n",
    "    let np = Python.import_module(\"numpy\")\n",
    "    let Image = Python.import_module(\"PIL.Image\")\n",
    "    let python_builtins = Python.import_module(\"builtins\")\n",
    "    original_image = Image.open(image_path)\n",
    "    original_image_shape = original_image.size\n",
    "    # Mojo can't take Python ints firectly to Mojo Ints\n",
    "    original_width  = original_image_shape[0].to_float64().to_int()\n",
    "    original_height = original_image_shape[1].to_float64().to_int()\n",
    "\n",
    "    multispectral_image = original_image.resize((original_width//4, original_width//4))\n",
    "    upscaled_multispectral_image = multispectral_image.resize((original_width, original_height))\n",
    "    panchromatic_image = original_image.convert(\"L\")\n",
    "\n",
    "    original_array = np.array(original_image)\n",
    "    upscaled_multispectral_array = np.array(upscaled_multispectral_image)\n",
    "    panchromatic_array = np.array(panchromatic_image)\n",
    "\n",
    "    return python_builtins.tuple(original_array, panchromatic_array, upscaled_multispectral_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = object(10.)\n",
    "b = object(4.)\n",
    "\n",
    "#print(a.to_float64() /b.to_float64())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40000000000000002\n"
     ]
    }
   ],
   "source": [
    "print(a.__pow__(-1)*b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.zeros((10, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "[[0. 0.]\n",
      " [0. 5.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(d[0][1])\n",
    "\n",
    "d.__setitem__((1, 1), 5.0)\n",
    "\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error: \u001b[0;1;31m\u001b[1mExpression [59]:24:111: \u001b[0m\u001b[1mcannot construct 'PythonObject' from 'object' value in operator argument\n",
      "\u001b[0m                pansharpened_array.__setitem__((i, j, k), upscaled_multispectral_array[i][j][k] * PythonObject(ratio))\n",
      "\u001b[0;1;32m                                                                                                  ~~~~~~~~~~~~^~~~~~~\n",
      "\u001b[0m\u001b[0m\n",
      "expression failed to parse (no further compiler diagnostics)"
     ]
    }
   ],
   "source": [
    "def naive_pansharpen_mojo(panchromatic_array: PythonObject, upscaled_multispectral_array: PythonObject, weights: PythonObject, inout pansharpened_array: PythonObject) -> PythonObject:\n",
    "\n",
    "\n",
    "    for i in range(panchromatic_array.shape[0]):\n",
    "        print(\"i\", i)\n",
    "        for j in range(panchromatic_array.shape[1]):\n",
    "            print(\"j\", j)\n",
    "            psuedo_pan = object(0)\n",
    "            sum_weights = object(0)\n",
    "            for k in range(upscaled_multispectral_array.shape[-1]):\n",
    "                print(\"k1\", k)\n",
    "                rhs = upscaled_multispectral_array[i][j][k]*weights[k]\n",
    "                psuedo_pan +=  rhs.to_float64()\n",
    "                print(\"k2\", k)\n",
    "                sum_weights += weights[k].to_float64()\n",
    "                print(\"k3\", k)\n",
    "            # objects do not yet implement __truediv__, but they do implement __pow__...\n",
    "            psuedo_pan = psuedo_pan * sum_weights.__pow__(-1)\n",
    "\n",
    "            ratio = panchromatic_array[i][j].to_float64() * psuedo_pan.__pow__(-1)\n",
    "            \n",
    "            for k in range(upscaled_multispectral_array.shape[-1]):\n",
    "                print(\"k4\", k)\n",
    "                pansharpened_array.__setitem__((i, j, k), upscaled_multispectral_array[i][j][k] * PythonObject(ratio))\n",
    "            \n",
    "    return pansharpened_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmark import Unit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays = prepare_toy_image(\"/home/ferdi/Workspace/pansharpen/treed_brain_512.jpeg\")\n",
    "toy_original_array = arrays[0]\n",
    "toy_panchromatic_array = arrays[1]\n",
    "toy_upscaled_multispectral_array = arrays[2]\n",
    "shape = toy_upscaled_multispectral_array.shape\n",
    "toy_pansharpened_array = np.zeros(shape)\n",
    "channel_dependant_luminance_perception = np.array([0.299, 0.587, 0.114])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i 0\n",
      "j 0\n",
      "k1 0\n",
      "k2 0\n",
      "k3 0\n",
      "k1 1\n",
      "Error: \n"
     ]
    }
   ],
   "source": [
    "naive_pansharpen_mojo(panchromatic_array = toy_panchromatic_array, upscaled_multispectral_array = toy_upscaled_multispectral_array, weights = channel_dependant_luminance_perception, pansharpened_array = toy_pansharpened_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_matmul_untyped(image_path: String, python_time: Float64, numpy_time: Float64):\n",
    "    arrays = prepare_toy_image(image_path)\n",
    "    toy_original_array = arrays[0]\n",
    "    toy_panchromatic_array = arrays[1]\n",
    "    toy_upscaled_multispectral_array = arrays[2]\n",
    "    \n",
    "    let np = Python.import_module(\"numpy\")\n",
    "    shape = toy_upscaled_multispectral_array.shape\n",
    "    toy_pansharpened_array = np.zeros(shape)\n",
    "    channel_dependant_luminance_perception = np.array([0.299, 0.587, 0.114])\n",
    "\n",
    "    @parameter\n",
    "    fn test_fn():\n",
    "        try:\n",
    "            _ = naive_pansharpen_mojo(panchromatic_array = toy_panchromatic_array, upscaled_multispectral_array = toy_upscaled_multispectral_array, weights = channel_dependant_luminance_perception, pansharpened_array = toy_pansharpened_array)\n",
    "        except:\n",
    "            pass\n",
    "    print(1)\n",
    "    let secs = benchmark.run[test_fn](max_runtime_secs=10).mean()\n",
    "    \n",
    "    let speedup : Float64 = python_time / secs\n",
    "    print(secs, \"seconds, a\", speedup, \"x speedup over Python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error: Execution was interrupted, reason: signal SIGSEGV: address not mapped to object (fault address: 0x0).\n",
      "The process has been left at the point where it was interrupted, use \"thread return -x\" to return to the state before expression evaluation.\n"
     ]
    }
   ],
   "source": [
    "benchmark_matmul_untyped(\"/home/ferdi/Workspace/pansharpen/treed_brain_512.jpeg\", naive_python_time, numpy_python_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensor import Tensor, TensorSpec, TensorShape\n",
    "from utils.index import Index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#let gdal = Python.import_module(\"osgeo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_image = Image.open(\"/home/ferdi/Workspace/pansharpen/treed_brain_512.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_image_shape = original_image.size\n",
    "# Mojo can't take Python ints firectly to Mojo Ints\n",
    "original_width  = original_image_shape[0].to_float64().to_int()\n",
    "original_height = original_image_shape[1].to_float64().to_int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_image.resize((4, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "multispectral_image = original_image.resize((original_width//4, original_height//4))\n",
    "grayscale_image = original_image.convert(\"L\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_array = np.array(original_image)\n",
    "multispectral_array = np.array(multispectral_image)\n",
    "grayscale_array = np.array(grayscale_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "upscaled_multispectral_image = multispectral_image.resize((original_width, original_height))\n",
    "upscaled_multispectral_array = np.array(upscaled_multispectral_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_dependant_luminance_perception = np.array([0.299, 0.587, 0.114])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "var image_tensor = Tensor[DType.uint8](original_height, original_width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(original_height):\n",
    "    for j in range(original_width):\n",
    "        image_tensor[Index(i, j)] = grayscale_array[i][j].to_float64().to_int()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 15)\n"
     ]
    }
   ],
   "source": [
    "print(Index(10, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n"
     ]
    }
   ],
   "source": [
    "print(image_tensor[0, 600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n"
     ]
    }
   ],
   "source": [
    "print(image_tensor[Index(0, 1000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pansharpen(panchromatic_array: np.ndarray, upscaled_multispectral_array: np.ndarray, weights: np.ndarray):\n",
    "    psuedo_pan_array = np.true_divide((upscaled_multispectral_array*weights).sum(axis=2), weights.sum())\n",
    "    ratio = grayscale_array/psuedo_pan_array\n",
    "    new_red = upscaled_multispectral_array[:, :, 0] * ratio\n",
    "    new_green = upscaled_multispectral_array[:, :, 1] * ratio\n",
    "    new_blue = upscaled_multispectral_array[:, :, 2] * ratio\n",
    "    pansharpened_array = np.stack([new_red, new_green, new_blue], axis=2)\n",
    "    return pansharpened_array"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mojo",
   "language": "mojo",
   "name": "mojo-jupyter-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "mojo"
   },
   "file_extension": ".mojo",
   "mimetype": "text/x-mojo",
   "name": "mojo"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
